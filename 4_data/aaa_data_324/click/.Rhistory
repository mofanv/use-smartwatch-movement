e0 <- z/(sigma[i])
for(j in 1:n){
e[j,] <- rnorm(n_d, mean = 0, sd = e0)
}
u3_e <- e + u3_
u3_e <- cbind(u3_e, sigma[i])
dat1 <- rbind(dat1, u3_e)
}
# 3*7*20
set.seed(123)
#equally divided independent variables into n parts
#ntest <- seq(30,100,by=10)
n = 30
n_d <- 10
#manufacturing errors loacte in the tolerance range
tolerance<-0.01
#manufacturing sigma performance level
sigma <- c(1,2,3)
z <- 0.3*10^-6
u1<-seq(100,250,by=25)*10^-6
u2<-0.2
u3<-seq(3,6,by=0.5)*10^-6
#choosing N levels (points) from the normal distribution curve
N<-length(u1)
# sampled n+1 points of x1 50~100 (50,75,100,125,150,175,200)
e <- matrix(nrow=n, ncol=n_d)
u1_e <- matrix(nrow=n, ncol=n_d)
set.seed(123)
dat1 <- data.frame()
dat2 <- data.frame()
for(u3_ in u3){
for(i in 1:length(sigma)){
e0 <- z/(sigma[i])
for(j in 1:n){
e[j,] <- rnorm(n_d, mean = 0, sd = e0)
}
u3_e <- e + u3_
u3_e <- cbind(u3_e, sigma[i])
dat1 <- rbind(dat1, u3_e)
}
}
View(dat1)
for(u3_ in u3){
for(i in 1:length(sigma)){
e0 <- z/(sigma[i])
for(j in 1:n){
e[j,] <- rnorm(n_d, mean = 0, sd = e0)
}
u3_e <- e + u3_
u3_e <- cbind(u3_e, sigma[i])
u3_e <- cbind(u3_e, u3_)
dat1 <- rbind(dat1, u3_e)
}
}
# 3*7*20
set.seed(123)
#equally divided independent variables into n parts
#ntest <- seq(30,100,by=10)
n = 30
n_d <- 10
#manufacturing errors loacte in the tolerance range
tolerance<-0.01
#manufacturing sigma performance level
sigma <- c(1,2,3)
z <- 0.3*10^-6
u1<-seq(100,250,by=25)*10^-6
u2<-0.2
u3<-seq(3,6,by=0.5)*10^-6
#choosing N levels (points) from the normal distribution curve
N<-length(u1)
# sampled n+1 points of x1 50~100 (50,75,100,125,150,175,200)
e <- matrix(nrow=n, ncol=n_d)
u1_e <- matrix(nrow=n, ncol=n_d)
set.seed(123)
dat1 <- data.frame()
dat2 <- data.frame()
for(u3_ in u3){
for(i in 1:length(sigma)){
e0 <- z/(sigma[i])
for(j in 1:n){
e[j,] <- rnorm(n_d, mean = 0, sd = e0)
}
u3_e <- e + u3_
u3_e <- cbind(u3_e, sigma[i])
u3_e <- cbind(u3_e, u3_)
dat1 <- rbind(dat1, u3_e)
}
}
View(dat1)
tab2 <- summarySEwithin(m="value", b="Age", w="style", i="subject", data = tab1)
## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
read.xls('/Users/mofan/Downloads/tasktime.xlsx')
read.csv('/Users/mofan/Downloads/tasktime.xlsx')
read.csv('/Users/mofan/Downloads/tasktime.csv')
tab1 <- read.csv('/Users/mofan/Downloads/tasktime.csv')
tab2 <- summarySEwithin(m="value", b="Age", w="style", i="subject", data = tab1)
tab1 <- read.csv('/Users/mofan/Downloads/tasktime.csv')
tab2 <- summarySEwithin(measurevar="value", betweenvars="Age",
withinvars="style", idvar="subject", data = tab1)
tab1 <- read.csv('/Users/mofan/Downloads/tasktime.csv')
tab2 <- summarySEwithin(measurevar="value", betweenvars="Age",
withinvars="style", idvar="subject", data = tab1)
tab1 <- read.csv('/Users/mofan/Downloads/tasktime.csv')
library(reshape2)
tab3 <- melt(tab1,
id.var=c("subject","Age"),
measure.vars=c("flat","skeuomorphic"),
variable.names="style")
library(reshape2)
tab3 <- melt(tab1,
id.var=c("subject","Age"),
measure.vars=c("flat","skeuomorphic"),
variable.names="style")
View(tab3)
library(reshape2)
tab3 <- melt(tab1,
id.var=c("subject","Age"),
measure.vars=c("flat","skeuomorphic"),
variable.names=("style"))
View(tab3)
tab3 <- melt(tab1,
id.var=c("subject","Age"),
measure.vars=c("flat","skeuomorphic"),
variable.name = "style")
View(tab3)
tab2 <- summarySEwithin(measurevar="value", betweenvars="Age",
withinvars="style", idvar="subject", data = tab3)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
tab1 <- read.csv('/Users/mofan/Downloads/tasktime.csv')
tab1$subject <-factor(tab1$subject)
tab1$Age <-factor(tab1$Age)
library(reshape2)
tab3 <- melt(tab1,
id.var=c("subject","Age"),
measure.vars=c("flat","skeuomorphic"),
variable.name = "style")
tab2 <- summarySEwithin(measurevar="value", betweenvars="Age",
withinvars="style", idvar="subject", data = tab3)
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
tab1 <- read.csv('/Users/mofan/Downloads/tasktime.csv')
tab1$subject <-factor(tab1$subject)
tab1$Age <-factor(tab1$Age)
library(reshape2)
tab3 <- melt(tab1,
id.var=c("subject","Age"),
measure.vars=c("flat","skeuomorphic"),
variable.name = "style")
tab2 <- summarySEwithin(measurevar="value", betweenvars="Age",
withinvars="style", idvar="subject", data = tab3)
View(tab3)
View(tab2)
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/task"
setwd(path)
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/task"
setwd(path)
old.file.names <- dir()
old.file.names[]
old.file.names[1]
file = "No10_Sp0_task.txt"
sub('_',file)
sub('_',file,)
sub('_','',file,)
strsplit('_',file)
file = "No10_Sp0_task.txt"
strsplit('_',file)
strsplit(file, '_')
strsplit(file, '_')[1]
strsplit(file, '_')[[1]]
strsplit(file, '_')[[1]][1]
file = "No10_Sp0_task.txt"
fileSplit = strsplit(file, '_')[[1]]
sub('No','',fileSplit[1])
file = "No10_Sp0_task.txt"
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
num(noNum)
int(noNum)
noNum + 10
as.numeric(noNum)
as.numeric(noNum) + 23
as.numeric(noNum) + 22
as.character(as.numeric(noNum) + 22)
'0' + as.character(as.numeric(noNum) + 22)
paste0('0', as.character(as.numeric(noNum) + 22))
paste0('No0', as.character(as.numeric(noNum) + 22))
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/task"
setwd(path)
old.file.names <- dir()
## new rule of files names
new.file.names <- sapply(old.file.names,function(file){
file = "No10_Sp0_task.txt"
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
file.rename(old.file.names,new.file.names)
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/task"
setwd(path)
old.file.names <- dir()
new.file.names <- sapply(old.file.names,function(file){
file = "No10_Sp0_task.txt"
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
new.file.names <- sapply(old.file.names,function(file){
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/task"
setwd(path)
old.file.names <- dir()
## new rule of files names
new.file.names <- sapply(old.file.names,function(file){
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
file.rename(old.file.names,new.file.names)
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/slip"
setwd(path)
old.file.names <- dir()
## new rule of files names
new.file.names <- sapply(old.file.names,function(file){
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
file.rename(old.file.names,new.file.names)
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/phase"
setwd(path)
old.file.names <- dir()
## new rule of files names
new.file.names <- sapply(old.file.names,function(file){
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
file.rename(old.file.names,new.file.names)
path <- "/Users/mofan/Documents/master_thesis/4_data/aaa_data_324/click"
setwd(path)
old.file.names <- dir()
## new rule of files names
new.file.names <- sapply(old.file.names,function(file){
fileSplit = strsplit(file, '_')[[1]]
noNum = sub('No','',fileSplit[1])
noStr = paste0('No0', as.character(as.numeric(noNum) + 22))
file = paste0(noStr, '_', fileSplit[2], '_', fileSplit[3])
return (file)
})
file.rename(old.file.names,new.file.names)
WORK_DICTIONARY = '/Users/mofan/Documents/master_thesis'
source('4_code/1_gait_click/4-1 click_space(tense).R')
source('4_code/1_gait_click/4-2 tense_data.R')
source('4_code/1_gait_click/4-3 tense_data_more.R')
source('4_code/1_gait_click/4-4 tense_data_more2.R')
library(ggplot2)
library(tidyr)
largest = mean(c(20.124003851837,23.151825934077,22.072407267240,25.041018866413,24.217047229278))
for(Sp in 1:5){
data0 = click_space(Sp)
tenseDATA = tense_data(data0)
tenseDATA = tense_data_more(tenseDATA)
dat = tense_data_more2(tenseDATA)
dat$mean_wind[which(dat$mean_wind == max(dat$mean_wind))] = largest # normalization
#dat = data0
wind.dt<-structure(list(Lon = dat$Lon,
Lat = dat$Lat,
mean_wind = dat$mean_wind,
wind_dir = dat$wind_dir),
row.names = c(NA, -nrow(dat)),
.Names = c("Lon", "Lat", "mean_wind", "wind_dir"),
class = c("tbl_df", "tbl", "data.frame"))
str0 = c('Stand','Strolling','Walking','Rushing','Jogging')
title = paste0(str0[Sp])
p <- ggplot(wind.dt,
aes(x = Lon,
y = -Lat,
fill = mean_wind,
angle = -wind_dir,
radius = mean_wind)) +
geom_raster() +
geom_spoke(arrow = arrow(length = unit(.05, 'inches'))) +
scale_fill_distiller(palette = "RdYlGn",name='Offset\nDistance') +
coord_equal(expand = 0) +
xlim(0,355) +
ylim(-360,0) +
#theme(legend.position = 'bottom',
#      legend.direction = 'horizontal') +
ggtitle(title)
png(paste0("4_results/interaction_feature/space/","touch_wind_Sp",Sp,".png"),width = 2000,height = 1950,res = 300)
print(p)
dev.off()
}
WORK_DICTIONARY = '/Users/mofan/Documents/master_thesis'
source('4_code/1_gait_click/4-1 click_space(tense).R')
source('4_code/1_gait_click/4-2 tense_data.R')
source('4_code/1_gait_click/4-3 tense_data_more.R')
source('4_code/1_gait_click/4-4 tense_data_more2.R')
library(ggplot2)
library(tidyr)
largest = mean(c(20.124003851837,23.151825934077,22.072407267240,25.041018866413,24.217047229278))
for(Sp in 1:5){
data0 = click_space(Sp)
tenseDATA = tense_data(data0)
tenseDATA = tense_data_more(tenseDATA)
dat = tense_data_more2(tenseDATA)
dat$mean_wind[which(dat$mean_wind == max(dat$mean_wind))] = largest # normalization
#dat = data0
wind.dt<-structure(list(Lon = dat$Lon,
Lat = dat$Lat,
mean_wind = dat$mean_wind,
wind_dir = dat$wind_dir),
row.names = c(NA, -nrow(dat)),
.Names = c("Lon", "Lat", "mean_wind", "wind_dir"),
class = c("tbl_df", "tbl", "data.frame"))
str0 = c('Stand','Strolling','Walking','Rushing','Jogging')
title = paste0(str0[Sp])
p <- ggplot(wind.dt,
aes(x = Lon,
y = -Lat,
fill = mean_wind,
angle = -wind_dir,
radius = mean_wind)) +
geom_raster() +
geom_spoke(arrow = arrow(length = unit(.05, 'inches'))) +
scale_fill_distiller(palette = "RdYlGn",name='Offset\nDistance') +
coord_equal(expand = 0) +
xlim(0,355) +
ylim(-360,0) +
#theme(legend.position = 'bottom',
#      legend.direction = 'horizontal') +
ggtitle(title)
png(paste0("4_results/interaction_feature/space/","touch_wind_Sp",Sp,".png"),width = 2000,height = 1950,res = 300)
print(p)
dev.off()
}
WORK_DICTIONARY = '/Users/mofan/Documents/master_thesis'
source('4_code/1_gait_click/4-1 click_space(tense).R')
source('4_code/1_gait_click/4-2 tense_data.R')
source('4_code/1_gait_click/4-3 tense_data_more.R')
source('4_code/1_gait_click/4-4 tense_data_more2.R')
WORK_DICTIONARY = '/Users/mofan/Documents/master_thesis'
source('4_code/1_gait_click/4-1 click_space(tense).R')
source('4_code/1_gait_click/4-2 tense_data.R')
source('4_code/1_gait_click/4-3 tense_data_more.R')
source('4_code/1_gait_click/4-4 tense_data_more2.R')
WORK_DICTIONARY = '/Users/mofan/Documents/master_thesis'
source('4_code/1_gait_click/4-1 click_space(tense).R')
WORK_DICTIONARY = '/Users/mofan/Documents/master_thesis'
source('4_code/1_gait_click/4-1 click_space(tense).R')
